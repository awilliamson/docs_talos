
<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <title>Talos User Manual</title>

    <style>
      .highlight table td { padding: 5px; }
.highlight table pre { margin: 0; }
.highlight .gh {
  color: #999999;
}
.highlight .sr {
  color: #f6aa11;
}
.highlight .go {
  color: #888888;
}
.highlight .gp {
  color: #555555;
}
.highlight .gs {
}
.highlight .gu {
  color: #aaaaaa;
}
.highlight .nb {
  color: #f6aa11;
}
.highlight .cm {
  color: #75715e;
}
.highlight .cp {
  color: #75715e;
}
.highlight .c1 {
  color: #75715e;
}
.highlight .cs {
  color: #75715e;
}
.highlight .c, .highlight .cd {
  color: #75715e;
}
.highlight .err {
  color: #960050;
}
.highlight .gr {
  color: #960050;
}
.highlight .gt {
  color: #960050;
}
.highlight .gd {
  color: #49483e;
}
.highlight .gi {
  color: #49483e;
}
.highlight .ge {
  color: #49483e;
}
.highlight .kc {
  color: #66d9ef;
}
.highlight .kd {
  color: #66d9ef;
}
.highlight .kr {
  color: #66d9ef;
}
.highlight .no {
  color: #66d9ef;
}
.highlight .kt {
  color: #66d9ef;
}
.highlight .mf {
  color: #ae81ff;
}
.highlight .mh {
  color: #ae81ff;
}
.highlight .il {
  color: #ae81ff;
}
.highlight .mi {
  color: #ae81ff;
}
.highlight .mo {
  color: #ae81ff;
}
.highlight .m, .highlight .mb, .highlight .mx {
  color: #ae81ff;
}
.highlight .sc {
  color: #ae81ff;
}
.highlight .se {
  color: #ae81ff;
}
.highlight .ss {
  color: #ae81ff;
}
.highlight .sd {
  color: #e6db74;
}
.highlight .s2 {
  color: #e6db74;
}
.highlight .sb {
  color: #e6db74;
}
.highlight .sh {
  color: #e6db74;
}
.highlight .si {
  color: #e6db74;
}
.highlight .sx {
  color: #e6db74;
}
.highlight .s1 {
  color: #e6db74;
}
.highlight .s {
  color: #e6db74;
}
.highlight .na {
  color: #a6e22e;
}
.highlight .nc {
  color: #a6e22e;
}
.highlight .nd {
  color: #a6e22e;
}
.highlight .ne {
  color: #a6e22e;
}
.highlight .nf {
  color: #a6e22e;
}
.highlight .vc {
  color: #ffffff;
}
.highlight .nn {
  color: #ffffff;
}
.highlight .nl {
  color: #ffffff;
}
.highlight .ni {
  color: #ffffff;
}
.highlight .bp {
  color: #ffffff;
}
.highlight .vg {
  color: #ffffff;
}
.highlight .vi {
  color: #ffffff;
}
.highlight .nv {
  color: #ffffff;
}
.highlight .w {
  color: #ffffff;
}
.highlight {
  color: #ffffff;
}
.highlight .n, .highlight .py, .highlight .nx {
  color: #ffffff;
}
.highlight .ow {
  color: #f92672;
}
.highlight .nt {
  color: #f92672;
}
.highlight .k, .highlight .kv {
  color: #f92672;
}
.highlight .kn {
  color: #f92672;
}
.highlight .kp {
  color: #f92672;
}
.highlight .o {
  color: #f92672;
}
    </style>
    <link href="stylesheets/screen.css" rel="stylesheet" media="screen" />
    <link href="stylesheets/print.css" rel="stylesheet" media="print" />
      <script src="javascripts/all.js"></script>
  </head>

  <body class="index" data-languages="[]">
    <a href="#" id="nav-button">
      <span>
        NAV
        <img src="images/navbar.png" alt="Navbar" />
      </span>
    </a>
    <div class="toc-wrapper">
      <img src="images/small_logo.png" class="logo" alt="Small logo" />
        <div class="search">
          <input type="text" class="search" id="input-search" placeholder="Search">
        </div>
        <ul class="search-results"></ul>
      <ul id="toc" class="toc-list-h1">
          <li>
            <a href="#introduction" class="toc-h1 toc-link" data-title="Introduction">Introduction</a>
          </li>
          <li>
            <a href="#getting-started" class="toc-h1 toc-link" data-title="Getting Started">Getting Started</a>
          </li>
          <li>
            <a href="#workflow" class="toc-h1 toc-link" data-title="Workflow">Workflow</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#p-repare" class="toc-h2 toc-link" data-title="(P)repare">(P)repare</a>
                  </li>
                  <li>
                    <a href="#o-ptimize" class="toc-h2 toc-link" data-title="(O)ptimize">(O)ptimize</a>
                  </li>
                  <li>
                    <a href="#d-eploy" class="toc-h2 toc-link" data-title="(D)eploy">(D)eploy</a>
                  </li>
                  <li>
                    <a href="#reporting-and-evaluation" class="toc-h2 toc-link" data-title="Reporting and Evaluation">Reporting and Evaluation</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#parameter-dictionary" class="toc-h1 toc-link" data-title="Parameter Dictionary">Parameter Dictionary</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#input-formats" class="toc-h2 toc-link" data-title="Input Formats">Input Formats</a>
                  </li>
                  <li>
                    <a href="#allowed-hyperparameters" class="toc-h2 toc-link" data-title="Allowed hyperparameters">Allowed hyperparameters</a>
                  </li>
                  <li>
                    <a href="#hidden-layers" class="toc-h2 toc-link" data-title="Hidden Layers">Hidden Layers</a>
                  </li>
                  <li>
                    <a href="#lr-normalizer" class="toc-h2 toc-link" data-title="LR Normalizer">LR Normalizer</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#models" class="toc-h1 toc-link" data-title="Models">Models</a>
          </li>
          <li>
            <a href="#optimization-strategies" class="toc-h1 toc-link" data-title="Optimization Strategies">Optimization Strategies</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#grid-search" class="toc-h2 toc-link" data-title="Grid search">Grid search</a>
                  </li>
                  <li>
                    <a href="#random-optimizers" class="toc-h2 toc-link" data-title="Random Optimizers">Random Optimizers</a>
                  </li>
                  <li>
                    <a href="#probabilistic-reduction" class="toc-h2 toc-link" data-title="Probabilistic reduction">Probabilistic reduction</a>
                  </li>
                  <li>
                    <a href="#early-stopping" class="toc-h2 toc-link" data-title="Early Stopping">Early Stopping</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#commands" class="toc-h1 toc-link" data-title="Commands">Commands</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#scan" class="toc-h2 toc-link" data-title="Scan()">Scan()</a>
                  </li>
                  <li>
                    <a href="#reporting" class="toc-h2 toc-link" data-title="Reporting()">Reporting()</a>
                  </li>
                  <li>
                    <a href="#predict" class="toc-h2 toc-link" data-title="Predict()">Predict()</a>
                  </li>
                  <li>
                    <a href="#evaluate" class="toc-h2 toc-link" data-title="Evaluate()">Evaluate()</a>
                  </li>
                  <li>
                    <a href="#deploy" class="toc-h2 toc-link" data-title="Deploy()">Deploy()</a>
                  </li>
                  <li>
                    <a href="#restore" class="toc-h2 toc-link" data-title="Restore()">Restore()</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#monitoring" class="toc-h1 toc-link" data-title="Monitoring">Monitoring</a>
          </li>
          <li>
            <a href="#gpu-support" class="toc-h1 toc-link" data-title="GPU Support">GPU Support</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#single-gpu-single-job" class="toc-h2 toc-link" data-title="Single GPU, Single Job">Single GPU, Single Job</a>
                  </li>
                  <li>
                    <a href="#single-gpu-multiple-jobs" class="toc-h2 toc-link" data-title="Single GPU, Multiple Jobs">Single GPU, Multiple Jobs</a>
                  </li>
                  <li>
                    <a href="#multi-gpu-single-job" class="toc-h2 toc-link" data-title="Multi-GPU, Single Job">Multi-GPU, Single Job</a>
                  </li>
                  <li>
                    <a href="#force-cpu" class="toc-h2 toc-link" data-title="Force CPU">Force CPU</a>
                  </li>
              </ul>
          </li>
          <li>
            <a href="#functional-model" class="toc-h1 toc-link" data-title="Functional Model">Functional Model</a>
          </li>
          <li>
            <a href="#troubleshooting" class="toc-h1 toc-link" data-title="Troubleshooting">Troubleshooting</a>
              <ul class="toc-list-h2">
                  <li>
                    <a href="#need-help" class="toc-h2 toc-link" data-title="Need help">Need help</a>
                  </li>
                  <li>
                    <a href="#found-an-issue" class="toc-h2 toc-link" data-title="Found an issue">Found an issue</a>
                  </li>
                  <li>
                    <a href="#common-errors" class="toc-h2 toc-link" data-title="Common errors">Common errors</a>
                  </li>
              </ul>
          </li>
      </ul>
        <ul class="toc-footer">
            <li><a href='https://github.com/autonomio/talos'>Code on Github</a></li>
        </ul>
    </div>
    <div class="page-wrapper">
      <div class="dark-box"></div>
      <div class="content">
        <h1 id='introduction'>Introduction</h1>
<p>Welcome to Talos! You can use Talos for hyperparameter optimization with Keras models. Talos allows you to use Keras models exactly as you would otherwise, and is built for and tested on Python 2 and 3.</p>

<blockquote>
<p>To install stable:</p>
</blockquote>
<pre class="highlight shell tab-shell"><code>pip install talos
</code></pre>
<blockquote>
<p>Latest dev version:</p>
</blockquote>
<pre class="highlight shell tab-shell"><code>pip install git+https://github.com/autonomio/talos.git@daily-dev
</code></pre>
<p>Talos incorporates grid, random, and probabilistic hyperparameter optimization strategies, with focus on maximizing the flexibility, efficiency, and result of random strategy. Talos users benefit from access to pseudo, quasi, true, and quantum random methods.  </p>

<p>Talos provides a fully automated <em>POD</em> (Prepare, Optimize, Deploy) pipeline that consistently yields state-of-the-art prediction results in a wide-range of prediction problems.</p>

<p>Talos is maintained by a non-profit foundation with 501(c)(3) status. The code is available on <a href="https://github.com/autonomio/talos">Github</a>.</p>
<h1 id='getting-started'>Getting Started</h1><pre class="highlight python tab-python"><code><span class="kn">import</span> <span class="nn">talos</span> <span class="k">as</span> <span class="n">ta</span>

<span class="n">p</span> <span class="o">=</span> <span class="p">{</span>
  <span class="c"># your parameter boundaries come here</span>
<span class="p">}</span>

<span class="k">def</span> <span class="nf">input_model</span><span class="p">():</span>
  <span class="c"># your model comes here</span>

<span class="n">ta</span><span class="o">.</span><span class="n">Scan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">input_model</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>Find code complete examples <a href="#">here</a></p>
</blockquote>

<p>To get started with your first experiment is easy. You need to have three things:</p>

<ul>
<li>a hyperparameter dictionary</li>
<li>a working Keras model</li>
<li>a Talos experiment</li>
</ul>

<p><strong>STEP 1</strong> &gt;&gt; In a regular Python dictionary, you declare the hyperparameters and the boundaries you want to include in the experiment.</p>

<p><strong>STEP 2</strong> &gt;&gt; In order to prepare a Keras model for a Talos experiment, you simply replace parameters you want to include in the scan, with references to the parameter dictionary.</p>

<p><strong>STEP 3</strong> &gt;&gt; To start the experiment, you input the parameter dictionary and the Keras model into Talos with the option for Grid, Random, or Probabilistic optimization strategy.</p>

<aside class="notice">
Setting a complex hyperparameter optimization experiment with Talos rarely takes longer than 5 minutes.
</aside>
<h1 id='workflow'>Workflow</h1>
<p>Talos follows <em>POD</em> (prepare, optimize, deploy) workflow, with additional functionality for evaluation and reporting, including plots for visual analysis.</p>
<h2 id='p-repare'>(P)repare</h2>
<p>Preparation involves the process of defining the hyperparameter space for the experiment, and the setting of the experiment options such as choosing of the optimization strategy.</p>

<p>See <a href="#parameter-dictionary">Parameter dictionary</a>, <a href="#models">Models</a>, and <a href="#scan">Scan()</a>.</p>
<h2 id='o-ptimize'>(O)ptimize</h2>
<p>Optimization involves the automated process of finding an optimal hyperparameter combination for a well generalizing model for a given prediction task.</p>

<p>See <a href="#optimization-strategies">Optimization strategies</a> and <a href="#reporting">Reporting</a>.</p>
<h2 id='d-eploy'>(D)eploy</h2>
<p>Deployment involves the automated process of storing locally the required assets for local or remote deployment of a predictive model for production purpose.</p>

<p>See <a href="#deploy">Deploy()</a> and <a href="#predict">Predict</a></p>
<h2 id='reporting-and-evaluation'>Reporting and Evaluation</h2>
<p>In addition Talos provides several useful tools for analysis and evaluation of experiments, including live updating plots for epoch-by-epoch visual analysis of experiment progress.</p>

<p>See <a href="#evaluate">Evaluate</a>, <a href="#reporting">Reporting()</a> and <a href="#monitoring">Monitoring</a></p>
<h1 id='parameter-dictionary'>Parameter Dictionary</h1>
<p>The first step in an experiment is to decide the hyperparameters you want to use in the optimization process.</p>

<blockquote>
<p>Example parameter dictionary:</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">keras.activations</span> <span class="kn">import</span> <span class="n">relu</span><span class="p">,</span> <span class="n">elu</span>

<span class="n">p</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'first_neuron'</span><span class="p">:</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">48</span><span class="p">],</span>
    <span class="s">'activation'</span><span class="p">:</span> <span class="p">[</span><span class="n">relu</span><span class="p">,</span> <span class="n">elu</span><span class="p">],</span>
    <span class="s">'batch_size'</span><span class="p">:</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
<span class="p">}</span>
</code></pre>
<blockquote>
<p>Activations need to go in as objects and not strings</p>
</blockquote>

<p>In addition to standard Keras hyperparameters, Talos allows several extra conveniences such as the ability to include number of hidden layers in the process.</p>
<h2 id='input-formats'>Input Formats</h2>
<p>Parameters may be inputted in three distinct ways:</p>

<ul>
<li>as a set of discreet values in a list</li>
<li>as a range of values in a tuple</li>
<li>as a single value in list</li>
</ul>
<pre class="highlight python tab-python"><code><span class="c"># discreet values in a list</span>
<span class="n">p</span> <span class="o">=</span> <span class="p">{</span><span class="s">'first_neuron'</span><span class="p">:</span> <span class="p">[</span><span class="mi">12</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">96</span><span class="p">]}</span>

<span class="c"># range of values in a tuple</span>
<span class="n">p</span> <span class="o">=</span> <span class="p">{</span><span class="s">'first_neuron'</span><span class="p">:</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">48</span><span class="p">,</span> <span class="mi">10</span><span class="p">)}</span>

<span class="c"># a single value</span>
<span class="n">p</span> <span class="o">=</span> <span class="p">{</span><span class="s">'first_neuron'</span><span class="p">:</span> <span class="p">[</span><span class="mi">12</span><span class="p">]}</span>

</code></pre>
<p>When a tuple is used for a range of values, the first value is <em>min</em>, second value is <em>max</em> and the third value is <em>steps</em>.</p>
<h2 id='allowed-hyperparameters'>Allowed hyperparameters</h2>
<p>Generally speaking, whatever hyperparameters you can use in Keras, you can include in a Talos experiment as simply as including the hyperparameter label together with the desired values or the range of values in the parameter dictionary.</p>

<p>If you find that a given hyperparamter is not supported, <a href="https://github.com/autonomio/talos/issues/new/choose">create an issue</a> on Github.</p>
<h2 id='hidden-layers'>Hidden Layers</h2>
<p>Each hidden layer is followed by a Dropout regularizer. If this is undesired, set dropout to 0 with <code>dropout: [0]</code> in the parameter dictionary.</p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">talos.model.layers</span> <span class="kn">import</span> <span class="n">hidden_layers</span>

<span class="k">def</span> <span class="nf">input_model</span><span class="p">():</span>
  <span class="c"># model prep and input layer...</span>
  <span class="n">hidden_layers</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
  <span class="c"># rest of the model...</span>
</code></pre>
<p>Including hidden_layers in a model allows the use of number of hidden layers as an optimization parameter.</p>

<aside class="notice">
When hidden layers are used, <code>dropout, hidden_layers, and first_neuron</code> parameters must be included in the parameter dictionary.
</aside>
<h2 id='lr-normalizer'>LR Normalizer</h2>
<p>As one experiment may include more than one optimizer, and optimizers generally have default learning rates in different order of magnitudes, lr_normalizer can be used to allow simultanously including different optimizers and different degrees of learning rates into the Talos experiment.</p>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">talos.model.normalizers</span> <span class="kn">import</span> <span class="n">lr_normalizer</span>
<span class="c"># model first part is here ...</span>
<span class="n">model</span><span class="o">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s">'binary_crossentropy'</span><span class="p">,</span>
              <span class="n">optimizer</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="s">'optimizer'</span><span class="p">](</span><span class="n">lr_normalizer</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s">'lr'</span><span class="p">],</span> <span class="n">params</span><span class="p">[</span><span class="s">'optimizer'</span><span class="p">])),</span>
              <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s">'accuracy'</span><span class="p">])</span>
<span class="c"># model ending part is here ...</span>
</code></pre>
<aside class="notice">
The lr_normalizer needs to be invoked explicitly
</aside>
<h1 id='models'>Models</h1>
<p>The purpose of Talos is to allow you to continue working with Keras models exactly the way you are used to, and to allow leveraging the flexibility available in Keras without adding any restrictions. <strong>Any Keras model can be used in a Talos experiment</strong> and Talos does not introduce any new syntax to Keras models.</p>

<blockquote>
<p>A single line example of modifying the model</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="c"># In original Keras model</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>

<span class="c"># In Talos</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s">'first_neuron'</span><span class="p">],</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">))</span>

</code></pre>
<p>In order to use a Keras model in an experiment, you have to modify a working Keras model in a way where the hyperparameter references are replaced with the parameter dictionary references.</p>

<p>You can find several examples of modified Keras models ready for a Talos experiment <a href="https://github.com/autonomio/talos/blob/master/talos/examples/models.py">here</a> and a code complete example with parameter dictionary and experiment configuration <a href="https://github.com/autonomio/talos/blob/master/examples/iris.py">here</a>.</p>

<aside class="notice">
You should always make sure that your Keras model works as-is before using it in a Talos experiment.
</aside>
<h1 id='optimization-strategies'>Optimization Strategies</h1>
<p>Talos incorporates several optimization strategies:</p>

<ul>
<li>Grid search</li>
<li>Random search</li>
<li>Probabilistic reduction</li>
</ul>
<h2 id='grid-search'>Grid search</h2>
<p>Grid search is the default optimization strategy; all hyperparameter permutations in a given parameter boundary will be processed. Grid search is not recommended for anything but very small permutation spaces. A better option is to use random optimization strategy by invoking <code>grid_downsample</code> in Scan().</p>
<h2 id='random-optimizers'>Random Optimizers</h2>
<p>Random search is the recommended optimization strategy in Talos. This is invoked through the &#39;grid_downsample&#39; argument in Scan() with a floating point value in the experiment options. For example, to randomly pick 10% of the permutations, a grid_downsample value of 0.1 is used.</p>
<pre class="highlight python tab-python"><code><span class="n">Scan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
     <span class="n">params</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
     <span class="n">model</span><span class="o">=</span><span class="n">input_model</span><span class="p">,</span>
     <span class="n">grid_downsample</span><span class="o">=.</span><span class="mi">1</span><span class="p">)</span>
</code></pre>
<p>Several pseudo, quasi, true, and quantum random methods are provided for random searches. These are controlled through the &#39;random_method&#39; argument in Scan().</p>
<pre class="highlight python tab-python"><code><span class="n">Scan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
     <span class="n">params</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
     <span class="n">model</span><span class="o">=</span><span class="n">input_model</span><span class="p">,</span>
     <span class="n">grid_downsample</span><span class="o">=.</span><span class="mi">1</span><span class="p">,</span>
     <span class="n">random_method</span><span class="o">=</span><span class="n">quantum</span><span class="p">)</span>
</code></pre>
<ul>
<li>Quantum</li>
<li>Ambient sound</li>
<li>Halton sequence</li>
<li>Sobol sequence</li>
<li>Korobov matrix</li>
<li>Latin hypercube</li>
<li>Latin hypercube with Sudoku style constraint</li>
<li>Improved Latin hypercube (very slow)</li>
<li>Uniform Mersenne</li>
<li>Uniform cryptographically secure</li>
</ul>

<p>Each random method results in a different degree of discrepancy; whereas uniform random methods tend to have higher discrepancy, as does quantum and ambient sound, hypercube and Korobov have lower.  </p>
<h2 id='probabilistic-reduction'>Probabilistic reduction</h2>
<p>The probabilistic reducers can be used together with a Grid search, or together with any of the Random methods. The reducer makes a stop between set number of rounds i.e. &#39;reduction_interval&#39; and uses a probabilistic method to remove poorly performing parameter configurations from the remaining search space.</p>

<p>Several parameters are related with this:</p>

<p><strong>Reduction Method:</strong> Currently only one reduction method is supported &#39;correlation&#39;.</p>

<p><strong>Reduction Interval:</strong> The number of rounds between each reduction stop.</p>

<p><strong>Reduction Window:</strong> The number of rounds to look back for input signals (e.g. when reduction_window is 50, the results of the last 50 rounds are used for inference)</p>

<p><strong>Reduction Threshold:</strong> A floating point value between 0 and 1, where 1 is perfect correlation and 0 is no correlation. The lower the correlation, the less significant a given hyperparameter is with results.</p>

<p><strong>Reduction Metric:</strong> The metric against which optimization is performed (e.g. &#39;val_acc&#39; or &#39;fmeasure&#39;)</p>

<p><strong>Reduce Loss:</strong> If &#39;reduction_metric&#39; is a loss metric, then this needs to be True.</p>
<h2 id='early-stopping'>Early Stopping</h2>
<p>The time that it takes to get to the desired result may be dramatically reduced by using an early stopping functionality. It is good to note though, that from the hyperparameter optimization standpoint, early stopping is not easy to get right, and it&#39;s often better to do without it. Early stopping needs to be invoked through Talos.</p>

<blockquote>
<p>Example for using the early_stopper callback
```python
from talos.model.early_stopper import early_stopper</p>
</blockquote>

<p>out = model.fit(x_train, y_train,
                batch_size=params[&#39;batch_size&#39;],
                epochs=params[&#39;epochs&#39;],
                verbose=0,
                validation_data=[x_val, y_val],
                callbacks=early_stopper(params[&#39;epochs&#39;], mode=&#39;strict&#39;))
```</p>
<h3 id='early_stopper-parameters'><code>early_stopper</code> parameters</h3>
<table><thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>epochs</code></td>
<td>NA</td>
<td>used for moderate mode</td>
</tr>
<tr>
<td><code>monitor</code></td>
<td>val_loss</td>
<td>the value to be monitored</td>
</tr>
<tr>
<td><code>mode</code></td>
<td>moderate</td>
<td>moderate, strict, or custom</td>
</tr>
<tr>
<td><code>min_delta</code></td>
<td>user input</td>
<td>rate of change at which point flag is raised</td>
</tr>
<tr>
<td><code>patience</code></td>
<td>user input</td>
<td>number of epochs before termination from flag</td>
</tr>
</tbody></table>

<p>The <code>mode</code> has three options and effects the point at which the flag is raised, and the number of epochs before termination on flag:</p>

<p><strong>moderate:</strong> If the value is not changing for 10th of the total epochs</p>

<p><strong>strict:</strong> If the value is not changing for 2 epochs</p>

<p><strong>custom:</strong> Input needs to be a list or tuple with two integers, where the first integer is <code>min_delta</code> and the second is <code>patience</code>.</p>
<h1 id='commands'>Commands</h1><h2 id='scan'>Scan()</h2>
<blockquote>
<p>Starting a simple quantum random experiment</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">Scan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
     <span class="n">params</span><span class="o">=</span><span class="n">p</span><span class="p">,</span>
     <span class="n">model</span><span class="o">=</span><span class="n">input_model</span><span class="p">,</span>
     <span class="n">random_method</span><span class="o">=</span><span class="n">quantum</span><span class="p">)</span>
</code></pre>
<p>The experiment is configured and started through the <a href="https://github.com/autonomio/talos/blob/master/talos/scan/Scan.py">Scan()</a> command. All of the options effecting the experiment, other than the hyperparameters themselves, are configured through the Scan arguments. The most common use-case is where ~10 arguments are invoked.</p>
<h3 id='scan-arguments'>Scan Arguments</h3>
<table><thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>x</code></td>
<td>user input</td>
<td>prediction features</td>
</tr>
<tr>
<td><code>y</code></td>
<td>user input</td>
<td>prediction outcome variable</td>
</tr>
<tr>
<td><code>params</code></td>
<td>user input</td>
<td>the parameter dictionary</td>
</tr>
<tr>
<td><code>model</code></td>
<td>user input</td>
<td>the Keras model as a function</td>
</tr>
<tr>
<td><code>dataset_name</code></td>
<td>None</td>
<td>Used for experiment log</td>
</tr>
<tr>
<td><code>experiment_no</code></td>
<td>None</td>
<td>Used for experiment log</td>
</tr>
<tr>
<td><code>x_val</code></td>
<td>None</td>
<td>validation data for x</td>
</tr>
<tr>
<td><code>y_val</code></td>
<td>None</td>
<td>validation data for y</td>
</tr>
<tr>
<td><code>val_split</code></td>
<td>.3</td>
<td>validation data split ratio</td>
</tr>
<tr>
<td><code>shuffle</code></td>
<td>True</td>
<td>if the data should be shuffled or not</td>
</tr>
<tr>
<td><code>random_method</code></td>
<td>&#39;uniform_mersenne&#39;</td>
<td>the random method to be used</td>
</tr>
<tr>
<td><code>search_method</code></td>
<td>&#39;random&#39;</td>
<td>the order in which permutations are checked</td>
</tr>
<tr>
<td><code>reduction_method</code></td>
<td>None</td>
<td>type of probabilistic reduction is used</td>
</tr>
<tr>
<td><code>reduction_interval</code></td>
<td>50</td>
<td>number of permutations after which reduction is applied</td>
</tr>
<tr>
<td><code>reduction_window</code></td>
<td>20</td>
<td>the look back window for reduction process</td>
</tr>
<tr>
<td><code>grid_downsample</code></td>
<td>None</td>
<td>A float to indicate fraction for random sampling</td>
</tr>
<tr>
<td><code>reduction_threshold</code></td>
<td>0.2</td>
<td>The threshold at which reduction is applied</td>
</tr>
<tr>
<td><code>reduction_metric</code></td>
<td>&#39;val_acc&#39;</td>
<td>The metric to be used for reduction</td>
</tr>
<tr>
<td><code>reduce_loss</code></td>
<td>False</td>
<td>If reduction_metric is a loss function</td>
</tr>
<tr>
<td><code>round_limit</code></td>
<td>None</td>
<td>Maximum number of permutations in the experiment</td>
</tr>
<tr>
<td><code>talos_log_name</code></td>
<td>&#39;talos.log&#39;</td>
<td>Name of the master log</td>
</tr>
<tr>
<td><code>debug</code></td>
<td>False</td>
<td>Turn on debug messages</td>
</tr>
<tr>
<td><code>seed</code></td>
<td>None</td>
<td>Seed for random states</td>
</tr>
<tr>
<td><code>clear_tf_session</code></td>
<td>True</td>
<td>Clear tensorflow session after each round</td>
</tr>
<tr>
<td><code>disable_progress_bar</code></td>
<td>False</td>
<td>Show live updating progress bar</td>
</tr>
<tr>
<td><code>functional_model</code></td>
<td>False</td>
<td>For functional model support</td>
</tr>
<tr>
<td><code>last_epoch_value</code></td>
<td>False</td>
<td>Reporting last epoch value in log</td>
</tr>
<tr>
<td><code>print_params</code></td>
<td>False</td>
<td>Print each permutation hyperparameters</td>
</tr>
</tbody></table>

<aside class="notice"> x, y, params, and model are the only needed arguments to start the experiment, all other are optional.</aside>
<h3 id='scan-object'>Scan Object</h3>
<p>The scan object has several attributes that are used for <code>Reporting()</code>, <code>Predict()</code> and <code>Deploy()</code>, but may also be useful to access directly. The namespace only consist of meaningful attributes.</p>
<pre class="highlight python tab-python"><code>
<span class="c"># returns the results dataframe</span>
<span class="n">h</span><span class="o">.</span><span class="n">data</span>

<span class="c"># returns the experiment configuration details</span>
<span class="n">h</span><span class="o">.</span><span class="n">details</span>

<span class="c"># returns the epoch entropy dataframe</span>
<span class="n">h</span><span class="o">.</span><span class="n">peak_epochs_df</span>

<span class="c"># returns the saved models (json)</span>
<span class="n">h</span><span class="o">.</span><span class="n">saved_models</span>

<span class="c"># returns the saved model weights</span>
<span class="n">h</span><span class="o">.</span><span class="n">saved_weights</span>

<span class="c"># returns x data</span>
<span class="n">h</span><span class="o">.</span><span class="n">x</span>

<span class="c"># returns y data</span>
<span class="n">h</span><span class="o">.</span><span class="n">y</span>

</code></pre><h2 id='reporting'>Reporting()</h2>
<p>The experiment results can be analyzed through the <a href="https://github.com/autonomio/talos/blob/master/talos/utils/reporting.py">Reporting()</a> command. The reporting consist of access to several meaningful signals related with the experiment, together with a dataframe with results for each permutation, together with the corresponding hyperparameter configurations. Reporting may be used after Scan completes, or during an experiment (from a different shell / kernel).</p>

<blockquote>
<p>Using reporting</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">r</span> <span class="o">=</span> <span class="n">Reporting</span><span class="p">(</span><span class="s">'experiment_log.csv'</span><span class="p">)</span>

<span class="c"># returns the results dataframe</span>
<span class="n">r</span><span class="o">.</span><span class="n">data</span>

<span class="c"># returns the highest value for 'val_fmeasure'</span>
<span class="n">r</span><span class="o">.</span><span class="n">high</span><span class="p">(</span><span class="s">'val_fmeasure'</span><span class="p">)</span>

<span class="c"># returns the number of rounds it took to find best model</span>
<span class="n">r</span><span class="o">.</span><span class="n">rounds2high</span><span class="p">()</span>

<span class="c"># draws a histogram for 'val_acc'</span>
<span class="n">r</span><span class="o">.</span><span class="n">plot_hist</span><span class="p">()</span>
</code></pre>
<aside class="notice">
Reporting works by loading the experiment log .csv file which is saved locally as part of the experiment. The filename can be changed through dataset_name and experiment_no Scan arguments.
</aside>

<p>The evaluation of experiment results consist of Reporting and Predict classes.</p>
<h3 id='reporting-functions'>Reporting Functions</h3>
<p>See docstrings for each function for a more detailed description.</p>

<p><strong><code>high</code></strong> The highest result for a given metric</p>

<p><strong><code>rounds</code></strong>  The number of rounds in the experiment</p>

<p><strong><code>rounds2high</code></strong> The number of rounds it took to get highest result</p>

<p><strong><code>low</code></strong> The lowest result for a given metric</p>

<p><strong><code>correlate</code></strong> A dataframe with Spearman correlation against a given metric</p>

<p><strong><code>plot_line</code></strong> A round-by-round line graph for a given metric</p>

<p><strong><code>plot_hist</code></strong> A histogram for a given metric where each observation is a permutation</p>

<p><strong><code>plot_corr</code></strong> A correlation heatmap where a single metric is compared against hyperparameters</p>

<p><strong><code>table</code></strong> A sortable dataframe with a given metric and hyperparameters</p>

<p><strong><code>best_params</code></strong> A dictionary of parameters from the best model</p>
<h3 id='reporting-arguments'>Reporting Arguments</h3>
<table><thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td>filename</td>
<td>None</td>
<td>name of the file with experiment log</td>
</tr>
</tbody></table>
<h2 id='predict'>Predict()</h2>
<p>In order to identify the best model from a given experiment, or to perform predictions with model/s, the <a href="[Reporting()](https://github.com/autonomio/talos/blob/master/talos/utils/predict.py)">Predict()</a> command can be used.</p>

<blockquote>
<p>Using predict</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="n">p</span> <span class="o">=</span> <span class="n">Predict</span><span class="p">(</span><span class="s">'scan_object'</span><span class="p">)</span>

<span class="c"># returns model_id for best performing model</span>
<span class="n">r</span><span class="o">.</span><span class="n">best_model</span><span class="p">(</span><span class="n">metric</span><span class="o">=</span><span class="s">'val_fmeasure'</span><span class="p">)</span>

<span class="c"># returns predictions for input x</span>
<span class="n">r</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c"># performs a 10-fold cross-validation for multi-class prediction</span>
<span class="n">r</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">folds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s">'macro'</span><span class="p">)</span>
</code></pre><h3 id='predict-functions'>Predict Functions</h3>
<p>See docstring for each function for a more detailed information, and the required input arguments.</p>

<p><strong><code>load_model</code></strong> Loads the Keras model with weights so it can be used in the local environment for predictions or other purpose. Requires <code>model_id</code> as argument. The <code>model_id</code> corresponds with the round in the experiment.</p>

<p><strong><code>best_model</code></strong> Identifies the <code>model_id</code> for the best performing model based on a given metric (e.g. &#39;val_fmeasure&#39;).</p>

<p><strong><code>predict</code></strong> Makes predictions based on input <code>x</code> and <code>model_id</code>. If <code>model_id</code> is not given, best model will be used.</p>

<p><strong><code>predict_classes</code></strong> Same as predict, but predicts classes.</p>

<p><strong><code>evaluate</code></strong> Evaluates models using a k-fold crossvalidation.</p>
<h3 id='predict-arguments'>Predict Arguments</h3>
<table><thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>scan_object</code></td>
<td>None</td>
<td>the object from Scan() after experiment is completed</td>
</tr>
</tbody></table>
<h2 id='evaluate'>Evaluate()</h2>
<p>The models that result from the experiment <code>Scan</code> object can be evaluated with <code>Evaluate()</code>. This way one or more models may be picked for deployment using k-fold cross-validation in a straightforward manner.</p>

<blockquote>
<p>Evaluating model generality</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">talos</span> <span class="kn">import</span> <span class="n">Evaluate</span>

<span class="c"># create the evaluate object</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">Evaluate</span><span class="p">(</span><span class="n">scan_object</span><span class="p">)</span>

<span class="c"># perform the evaluation</span>
<span class="n">e</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s">'macro'</span><span class="p">)</span>
</code></pre>
<p>NOTE: It&#39;s very important to save part of your data for evaluation, and keep it completely separated from the data you use for the actual experiment. A good approach would be where 50% of the data is saved for evaluation.</p>
<h3 id='evaluate-functions'>Evaluate Functions</h3>
<p>See the function docstring for a more detailed description.</p>

<p><strong><code>evaluate</code></strong> The highest result for a given metric</p>
<h3 id='evaluate-arguments'>Evaluate Arguments</h3>
<table><thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td>x</td>
<td>NA</td>
<td>the predictor data x</td>
</tr>
<tr>
<td>y</td>
<td>NA</td>
<td>the prediction data y (truth)</td>
</tr>
<tr>
<td>model_id</td>
<td>None</td>
<td>the model_id to be used</td>
</tr>
<tr>
<td>folds</td>
<td>None</td>
<td>number of folds to be used for cross-validation</td>
</tr>
<tr>
<td>shuffle</td>
<td>None</td>
<td>if data is shuffled before splitting</td>
</tr>
<tr>
<td>average</td>
<td>&#39;binary&#39;</td>
<td>&#39;binary&#39;, &#39;micro&#39;, &#39;macro&#39;, &#39;samples&#39;, or &#39;weighted&#39;</td>
</tr>
<tr>
<td>metric</td>
<td>None</td>
<td>the metric against which the validation is performed</td>
</tr>
<tr>
<td>asc</td>
<td>None</td>
<td>should be True if metric is a loss</td>
</tr>
</tbody></table>

<aside class='notice'> The above arguments are for the <code>evaluate</code> attribute of the <code>Evaluate</code> object.</aside>
<h2 id='deploy'>Deploy()</h2>
<blockquote>
<p>A successful experiment can be deployed easily</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">talos</span> <span class="kn">import</span> <span class="n">Deploy</span>

<span class="n">Deploy</span><span class="p">(</span><span class="n">scan_object</span><span class="p">,</span> <span class="s">'experiment_name'</span><span class="p">)</span>
</code></pre>
<p>When you&#39;ve achieved a successful result, you can use <code>Deploy()</code> to prepare a production ready package that can be easily transferred to another environment or system, or sent or uploaded. The deployment package will consists of the best performing model, which is picked automatically against &#39;val_acc&#39; unless stated with <code>metric</code> argument.</p>

<p>The deploy package consists of:</p>

<ul>
<li>details of the scan (details.txt)</li>
<li>model weights (model.h5)</li>
<li>model json (model.json)</li>
<li>results of the experiment (results.csv)</li>
<li>sample of x data (x.csv)</li>
<li>sample of y data (y.csv)</li>
</ul>

<p>The package can be restored into a copy of the original Scan object using the <code>Restore()</code> command.</p>
<h3 id='deploy-arguments'>Deploy Arguments</h3>
<table><thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>scan_object</code></td>
<td>None</td>
<td>a <code>Scan</code> object</td>
</tr>
<tr>
<td><code>model_name</code></td>
<td>None</td>
<td>a string value as the name of experiment</td>
</tr>
<tr>
<td><code>metric</code></td>
<td>&#39;val_acc&#39;</td>
<td>metric against which best model is picked</td>
</tr>
<tr>
<td><code>asc</code></td>
<td>False</td>
<td>use True for loss functions</td>
</tr>
</tbody></table>
<h2 id='restore'>Restore()</h2>
<blockquote>
<p>The Deploy package can be read back to an object</p>
</blockquote>
<pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">talos</span> <span class="kn">import</span> <span class="n">Restore</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">Restore</span><span class="p">(</span><span class="n">scan_object</span><span class="p">,</span> <span class="s">'experiment_name'</span><span class="p">)</span>
</code></pre>
<p>The <code>Deploy()</code> .zip package can be read back into a copy of the original experiment assets with <code>Restore()</code>. The object consists of:</p>

<ul>
<li>details of the scan</li>
<li>model</li>
<li>results of the experiment</li>
<li>sample of x data</li>
<li>sample of y data</li>
</ul>
<h3 id='restore-arguments'>Restore Arguments</h3>
<table><thead>
<tr>
<th>Parameter</th>
<th>Default</th>
<th>Description</th>
</tr>
</thead><tbody>
<tr>
<td><code>path_to_zip</code></td>
<td>None</td>
<td>full path to the <code>Deploy</code> asset zip file</td>
</tr>
</tbody></table>
<h1 id='monitoring'>Monitoring</h1>
<p>There are several options for monitoring the experiment.</p>
<pre class="highlight python tab-python"><code><span class="c"># turn off progress bar</span>
<span class="n">Scan</span><span class="p">(</span><span class="n">disable_progress_bar</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="c"># enable live training plot</span>
<span class="kn">from</span> <span class="nn">talos</span> <span class="kn">import</span> <span class="n">live</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span>
                <span class="n">Y</span><span class="p">,</span>
                <span class="n">epochs</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                <span class="n">callbacks</span><span class="o">=</span><span class="p">[</span><span class="n">live</span><span class="p">()])</span>

<span class="c"># turn on parameter printing</span>
<span class="n">Scan</span><span class="p">(</span><span class="n">print_params</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre>
<p><strong>Progress Bar :</strong> A round-by-round updating progress bar that shows the remaining rounds, together with a time estimate to completion. Progress bar is on by default.</p>

<p><strong>Live Monitoring :</strong> Live monitoring provides an epoch-by-epoch updating line graph that is enabled through the <code>live()</code> custom callback.</p>

<p><strong>Round Hyperparameters :</strong> Displays the hyperparameters for each permutation. Does not work together with live monitoring.</p>
<h1 id='gpu-support'>GPU Support</h1>
<p>Talos supports scenarios where on a single system one or more GPUs are handling one or more simultaneous jobs. The base GPU support is handled by TensorFlow, so make sure that you have the GPU version of TensorFlow installed.</p>

<p>You can watch system GPU utilization anytime with:</p>

<p><code>watch -n0.5 nvidia-smi</code></p>
<h2 id='single-gpu-single-job'>Single GPU, Single Job</h2>
<p>Single GPU works out-of-the-box, as long as you have the GPU version of TensorFlow installed. In case you already have the CPU version installed, you have to uninstall TensorFlow and install the GPU version.</p>
<h2 id='single-gpu-multiple-jobs'>Single GPU, Multiple Jobs</h2>
<blockquote>
<p>Parallel Scans with multiple GPU system</p>
</blockquote>
<pre class="highlight python tab-python"><code>
<span class="kn">from</span> <span class="nn">talos.utils.gpu_utils</span> <span class="kn">import</span> <span class="n">parallel_gpu_jobs</span>

<span class="c"># split GPU memory in two for two parallel jobs</span>
<span class="n">parallel_gpu_jobs</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span>

</code></pre>
<blockquote>
<p>Run the above lines before the Scan() command</p>
</blockquote>

<p>A single GPU can be split to simultaneously perform several experiments. This is useful you want to work on more than one scope at one time, or when you&#39;re analyzing the results of an ongoing experiment with <code>Reporting()</code> and are ready to start the next experiment while keeping the first one running.</p>

<p><strong>NOTE:</strong> GPU memory needs to be reserved pro-actively i.e. once the experiment is already running with full GPU memory, part of the memory can no longer be allocated to a new experiment.</p>
<h2 id='multi-gpu-single-job'>Multi-GPU, Single Job</h2><pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">talos.utils.gpu_utils</span> <span class="kn">import</span> <span class="n">multi_gpu</span>

<span class="c"># split a single job to multiple GPUs</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">multi_gpu</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</code></pre>
<blockquote>
<p>Include the above line in the input model before model.compile()</p>
</blockquote>

<p>Multiple GPUs on a single machine can be assigned to work on a single machine in a parallelism fashion. This is useful when you have more than one GPU on a single machine, and want to speed up the experiment. Each GPU roughly speaking reduces compute time linearly.</p>
<h2 id='force-cpu'>Force CPU</h2><pre class="highlight python tab-python"><code><span class="kn">from</span> <span class="nn">talos.utils.gpu_utils</span> <span class="kn">import</span> <span class="n">force_cpu</span>

<span class="c"># Force CPU use on a GPU system</span>
<span class="n">force_cpu</span><span class="p">()</span>
</code></pre>
<blockquote>
<p>Run the above lines before the Scan() command</p>
</blockquote>

<p>Sometimes it&#39;s useful (for example when <code>batch_size</code> tends to be very small) to disable GPU and use CPU instead. This can be done simply by invoking <code>force_cpu()</code>.</p>
<h1 id='functional-model'>Functional Model</h1>
<p>Both Sequential and Functional Keras models are supported in Talos. The workflow would be otherwise the same, but you have to declare in <code>Scan()</code> with <code>functional_model=True</code> that the model is functional.</p>
<pre class="highlight python tab-python"><code>
<span class="n">Scan</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">p</span><span class="p">,</span> <span class="n">input_model</span><span class="p">,</span> <span class="n">functional_model</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

</code></pre><h1 id='troubleshooting'>Troubleshooting</h1>
<p>If you run into trouble with something, or things are not working as expected, there are several things to do:</p>
<h2 id='need-help'>Need help</h2>
<ul>
<li>Read this manual</li>
<li>See one of the <a href="https://github.com/autonomio/talos/tree/master/examples">examples</a></li>
<li>Ask a <a href="https://stackoverflow.com/questions/ask">question</a> on Stackoverflow</li>
<li>Ask <a href="https://gitter.im/_talos_/Lobby?source=orgpage">for help</a> in the Talos Gitter channel</li>
</ul>
<h2 id='found-an-issue'>Found an issue</h2>
<ul>
<li>See the <a href="https://github.com/autonomio/talos/issues">open</a> and <a href="https://github.com/autonomio/talos/issues?utf8=%E2%9C%93&amp;q=is%3Aissue+is%3Aclosed+">closed</a> issues on Github.</li>
<li>See the <a href="#common-errors">Common errors</a></li>
</ul>
<h2 id='common-errors'>Common errors</h2>
<p>There are several common user-related cases where resulting errors are simple to overcome.</p>
<h3 id='subprocess32-error'><code>subprocess32 error</code></h3>
<p>This might arise during the installation on Python2.7 systems. The error results from a dependency in matplotlib. The issue can be overcome by first installing an older version of matplotlib:</p>

<p><code>pip install matplotlib==1.5.3</code></p>
<h3 id='wrong-numpy-version'><code>wrong numpy version</code></h3>
<p>This might arise in Python2.7 systems. The issue is overcome by installing a specific version of Numpy:</p>

<p><code>pip install numpy==1.14.5</code></p>
<h3 id='typeerror-39-str-39-object-is-not-callable'><code>TypeError: &#39;str&#39; object is not callable</code></h3>
<p>This error comes as a result of listing optimizers as string values as opposed to the actual object name in the params dictionary. The solution is to use the object name instead.</p>
<h3 id='typeerror-unsupported-operand-type-s-for-39-int-39-and-39-numpy-str_-39'><code>TypeError: unsupported operand type(s) for +: &#39;int&#39; and &#39;numpy.str_&#39;</code></h3>
<p>Same as above.</p>
<h3 id='typeerror-39-numpy-str_-39-object-cannot-be-interpreted-as-an-integer'><code>TypeError: &#39;numpy.str_&#39; object cannot be interpreted as an integer</code></h3>
<p>Same as above.</p>
<h3 id='valueerror-could-not-interpret-optimizer-identifier-lt-class-39-keras-optimizers-adam-39-gt'><code>ValueError: Could not interpret optimizer identifier: &lt;class &#39;keras.optimizers.Adam&#39;&gt;</code></h3>
<p>This is the reverse of the above; when lr_normalizer is not used, string values for optimizers should be used in the params dictionary.</p>
<h3 id='keyerror-39-first_neuron-39'><code>KeyError: &#39;first_neuron&#39;</code></h3>
<p>The &#39;first_neuron&#39; hyperparameter is missing from the params dictionary, or it&#39;s called something else than &#39;first_neuron&#39;.</p>
<h3 id='keyerror-39-hidden_layers-39-or-keyerror-39-dropout-39'><code>KeyError: &#39;hidden_layers&#39; or KeyError: &#39;dropout&#39;</code></h3>
<p>When ever hidden_layers is applied in the model, hidden_layers and dropout parameters need to be included in the params dictionary</p>
<h3 id='attributeerror-39-history-39-object-has-no-attribute-39-keys-39'><code>AttributeError: &#39;History&#39; object has no attribute &#39;keys&#39;</code></h3>
<p>This happens when the input model has:</p>

<p><code>return model, out</code></p>

<p>You fix this by using the right order for the objects:</p>

<p><code>return out, model</code></p>

<aside class="notice"> If everything else fails, <a href=https://github.com/autonomio/talos/issues/new/choose> post a new issue </a> on Github.
</aside>

      </div>
      <div class="dark-box">
      </div>
    </div>
  </body>
</html>
